{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from monai.data import Dataset, decollate_batch\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.transforms import Activations, AsDiscrete, Compose\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bmmae.augmentations import get_val_seg_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(model, loader, device, threshold=0.5):\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=threshold)])\n",
    "        for batch_data in tqdm.tqdm(loader, desc=\"Validation...\"):\n",
    "            inputs, label = (batch_data[\"image\"].to(device), batch_data[\"label\"].to(device))\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            try:\n",
    "                outputs = outputs.as_tensor()\n",
    "            except:\n",
    "                pass\n",
    "                # put everything on cpu\n",
    "            outputs = outputs.cpu()\n",
    "            label = label.cpu()\n",
    "            outputs = [post_trans(i) for i in decollate_batch(outputs)]\n",
    "            dice_metric(y_pred=outputs, y=label)\n",
    "\n",
    "        dice = dice_metric.aggregate(\"none\").numpy()\n",
    "\n",
    "        mean_dice = np.nanmean(dice, axis=0) * 100\n",
    "        std_dice = np.nanstd(dice, axis=0) * 100\n",
    "    \n",
    "\n",
    "        mean_dice_tc = mean_dice[0]\n",
    "        mean_dice_wt = mean_dice[1]\n",
    "        mean_dice_et = mean_dice[2]\n",
    "\n",
    "        std_dice_tc = std_dice[0]\n",
    "        std_dice_wt = std_dice[1]\n",
    "        std_dice_et = std_dice[2]\n",
    "\n",
    "        print(\n",
    "            f\"DICE\"\n",
    "            f\"\\n et: {mean_dice_et:.1f} ± {std_dice_et:.1f}\"\n",
    "            f\"\\n tc: {mean_dice_tc:.1f} ± {std_dice_tc:.1f}\"\n",
    "            f\"\\n wt: {mean_dice_wt:.1f} ± {std_dice_wt:.1f}\"\n",
    "        )\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Wilcoxon\n",
    "The code below is used to perform the Wilcoxon test between the model with pre-training and the baselines, to actually observe if there is a significative improvement or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = [\"t1\", \"t1ce\", \"t2\", \"flair\"]\n",
    "val_patients = os.listdir(os.path.join(\"../rsna/BraTS2021\", \"val\"))\n",
    "val_files = [\n",
    "    {\n",
    "        \"image\": [\n",
    "            os.path.join(\"../rsna/BraTS2021/val/\", patient, f\"{patient}_{modality}.nii.gz\") for modality in modalities\n",
    "        ],\n",
    "        \"label\": os.path.join(\"../rsna/BraTS2021/val/\", patient, f\"{patient}_seg.nii.gz\"),\n",
    "    }\n",
    "    for patient in val_patients\n",
    "]\n",
    "val_dataset = Dataset(data=val_files, transform=get_val_seg_transforms())\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=len(modalities),\n",
    "    out_channels=3,\n",
    "    img_size=(128, 128, 128),\n",
    "    hidden_size=768,\n",
    "    mlp_dim=1536,\n",
    "    num_heads=12,\n",
    "    proj_type=\"conv\",\n",
    "    qkv_bias=True,\n",
    ")\n",
    "\n",
    "if len(modalities) > 1:\n",
    "    placeholder = \"-\".join(modalities)\n",
    "else:\n",
    "    placeholder = modalities[0]\n",
    "\n",
    "from bmmae.model import BMMAEViT\n",
    "from bmmae.tokenizers import MRITokenizer\n",
    "\n",
    "tokenizers = {\n",
    "    modality: MRITokenizer(patch_size=(16, 16, 16), img_size=(128, 128, 128), hidden_size=768)\n",
    "    for modality in modalities\n",
    "}\n",
    "\n",
    "vit = BMMAEViT(\n",
    "    modalities=modalities,\n",
    "    tokenizers=tokenizers,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=1536,\n",
    "    num_heads=12,\n",
    "    qkv_bias=True,\n",
    "    classification=False\n",
    ")\n",
    "\n",
    "model.vit = vit\n",
    "model.load_state_dict(torch.load(f\"pretrained_models/bmmae/seg_{placeholder}_False.pth\", weights_only=True))\n",
    "\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "dice_bmmae = eval_loop(model, val_loader, device)\n",
    "\n",
    "## FROM SCRATCH\n",
    "model = UNETR(\n",
    "    in_channels=len(modalities),\n",
    "    out_channels=3,\n",
    "    img_size=(128, 128, 128),\n",
    "    hidden_size=768,\n",
    "    mlp_dim=1536,\n",
    "    num_heads=12,\n",
    "    proj_type=\"conv\",\n",
    "    qkv_bias=True,\n",
    ")\n",
    "model.load_state_dict(torch.load(f\"pretrained_models/fs/seg_{placeholder}_True.pth\", weights_only=True))\n",
    "model.to(\"cuda:0\")\n",
    "model.eval()\n",
    "dice_fs = eval_loop(model, val_loader, device)\n",
    "\n",
    "\n",
    "## REGMAE\n",
    "model = UNETR(\n",
    "    in_channels=len(modalities),\n",
    "    out_channels=3,\n",
    "    img_size=(128, 128, 128),\n",
    "    hidden_size=768,\n",
    "    mlp_dim=1536,\n",
    "    num_heads=12,\n",
    "    proj_type=\"conv\",\n",
    "    qkv_bias=True,\n",
    ")\n",
    "model.load_state_dict(torch.load(f\"pretrained_models/REGMAE/seg_{placeholder}_False.pth\", weights_only=True))\n",
    "model.to(\"cuda:0\")\n",
    "model.eval()\n",
    "dice_mae = eval_loop(model, val_loader, device)\n",
    "\n",
    "\n",
    "## SIMCLR\n",
    "model = UNETR(\n",
    "    in_channels=len(modalities),\n",
    "    out_channels=3,\n",
    "    img_size=(128, 128, 128),\n",
    "    hidden_size=768,\n",
    "    mlp_dim=1536,\n",
    "    num_heads=12,\n",
    "    proj_type=\"conv\",\n",
    "    qkv_bias=True,\n",
    ")\n",
    "model.load_state_dict(torch.load(f\"pretrained_models/SIMCLR/seg_{placeholder}_False.pth\", weights_only=True))\n",
    "model.to(\"cuda:0\")\n",
    "model.eval()\n",
    "dice_simclr = eval_loop(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "def clean_nan(x, y=None):\n",
    "    # get both mask of x and y\n",
    "    mask_x = ~np.isnan(x)\n",
    "    mask_y = ~np.isnan(y) if y is not None else mask_x\n",
    "    # get the mask of the intersection of x and y\n",
    "    mask = mask_x & mask_y\n",
    "    return x[mask]\n",
    "\n",
    "\n",
    "print(\"------------------ REGMAE --------------------------\")\n",
    "print(\"p-value for DICE TC : \", wilcoxon(clean_nan(dice_bmmae[:, 0]), clean_nan(dice_mae[:, 0])).pvalue.round(5))\n",
    "print(\"p-value for DICE WT : \",wilcoxon(clean_nan(dice_bmmae[:, 1]), clean_nan(dice_mae[:, 1])).pvalue.round(5))\n",
    "print(\"p-value for DICE ET : \",wilcoxon(clean_nan(dice_bmmae[:, 2]), clean_nan(dice_mae[:, 2])).pvalue.round(5))\n",
    "print(\"------------------ SIMCLR --------------------------\")\n",
    "print(\"p-value for DICE TC : \", wilcoxon(clean_nan(dice_bmmae[:, 0]), clean_nan(dice_simclr[:, 0])).pvalue.round(5))\n",
    "print(\"p-value for DICE WT : \",wilcoxon(clean_nan(dice_bmmae[:, 1]), clean_nan(dice_simclr[:, 1])).pvalue.round(5))\n",
    "print(\"p-value for DICE ET : \",wilcoxon(clean_nan(dice_bmmae[:, 2]), clean_nan(dice_simclr[:, 2])).pvalue.round(5))\n",
    "print(\"------------------ FROM SCRATCH --------------------------\")\n",
    "print(\"p-value for DICE TC : \", wilcoxon(clean_nan(dice_bmmae[:, 0]), clean_nan(dice_fs[:, 0])).pvalue.round(5))\n",
    "print(\"p-value for DICE WT : \",wilcoxon(clean_nan(dice_bmmae[:, 1]), clean_nan(dice_fs[:, 1])).pvalue.round(5))\n",
    "print(\"p-value for DICE ET : \",wilcoxon(clean_nan(dice_bmmae[:, 2]), clean_nan(dice_fs[:, 2])).pvalue.round(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
